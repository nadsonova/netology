{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cIzRy9mljr6w"
   },
   "outputs": [],
   "source": [
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kWblAixfjtc4",
    "outputId": "3b5a94b3-8fda-4e91-9ea0-4ade0381b367"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUTfSQBLur7k"
   },
   "source": [
    "# 1. Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7qyMU54GuNOL",
    "outputId": "a2ac29e6-0705-4fa4-88cc-349addb375fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We need to uphold laws against discrimination — in hiring, and in housing, and in education, and in the criminal justice system. That is what our Constitution and our highest ideals require.\tНам нужно отстаивать законы против дискриминации при найме на работу, в жилищной сфере, в сфере образования и правоохранительной системе. Этого требуют наша Конституция и высшие идеалы.\tCC-BY 2.0 (France) Attribution: tatoeba.org #5762728 (BHO) & #6390439 (odexed)\n",
      "I've heard that you should never date anyone who is less than half your age plus seven. Tom is now 30 years old and Mary is 17. How many years will Tom need to wait until he can start dating Mary?\tЯ слышал, что никогда не следует встречаться с кем-то вдвое младше вас плюс семь лет. Тому 30 лет, a Мэри 17. Сколько лет Тому нужно ждать до тех пор, пока он сможет начать встречаться с Мэри?\tCC-BY 2.0 (France) Attribution: tatoeba.org #10068197 (CK) & #10644473 (notenoughsun)\n",
      "I do have one final ask of you as your president, the same thing I asked when you took a chance on me eight years ago. I'm asking you to believe, not in my ability to bring about change but in yours.\tУ меня же, как у вашего президента, есть к вам последняя просьба. Та же самая, что и восемь лет назад, когда вы оказали мне своё доверие. Я прошу вас верить, но не в мои способности добиться перемен, а в ваши.\tCC-BY 2.0 (France) Attribution: tatoeba.org #5762723 (BHO) & #6390123 (odexed)\n",
      "In today's world, we have to equip all our kids with an education that prepares them for success, regardless of what they look like, or how much their parents make, or the zip code that they live in.\tВ современном мире перед нами стоит задача дать всем нашим детям такое образование, которое настроит их на успех вне зависимости от того, как они выглядят, сколько зарабатывают их родители или какой у них почтовый индекс.\tCC-BY 2.0 (France) Attribution: tatoeba.org #3924477 (BHO) & #5968115 (odexed)\n",
      "Death is something that we're often discouraged to talk about or even think about, but I've realized that preparing for death is one of the most empowering things you can do. Thinking about death clarifies your life.\tСмерть - это зачастую то, разговоры или даже мысли о чем приводят в уныние, но я осознал, что готовность умереть наделяет силой, как ничто другое. Мысль о смерти вносит ясность в твою жизнь.\tCC-BY 2.0 (France) Attribution: tatoeba.org #1969892 (davearms) & #3231553 (kukla)\n",
      "At a moment when our economy is growing, our businesses are creating jobs at the fastest pace since the 1990s, and wages are starting to rise again, we have to make some choices about the kind of country we want to be.\tВ тот момент, когда наша экономика растёт, наши предприятия создают рабочие места наибольшими темпами, начиная с 90-х годов, а зарплаты снова начинают расти, мы должны принять ряд решений относительно того, какой страной мы хотим быть.\tCC-BY 2.0 (France) Attribution: tatoeba.org #3924474 (BHO) & #4509418 (odexed)\n",
      "When I was younger, I hated going to weddings. My grandmothers and aunts would huddle around me, poke me in the side, and giggle \"You're next! You're next!\" They only stopped this nonsense when I began to do the same thing at funerals.\tКогда я была помоложе, я ненавидела ходить на свадьбы. Мои бабушки и тётки толпились вокруг, тыкали меня в бок и говорили, посмеиваясь: «Ты следующая! Ты следующая!». Они перестали нести этот вздор только тогда, когда я начала делать то же самое на похоронах.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2776770 (AlanF_US) & #4311406 (odexed)\n",
      "Since there are usually multiple websites on any given topic, I usually just click the back button when I arrive on any webpage that has pop-up advertising. I just go to the next page found by Google and hope for something less irritating.\tПоскольку сайтов, посвящённых какой-либо теме, как правило, несколько, я обычно просто нажимаю на кнопку \"назад\", если попадаю на страницу со всплывающей рекламой. Я просто перехожу на следующую страницу, найденную гуглом, и надеюсь найти что-то менее раздражающее.\tCC-BY 2.0 (France) Attribution: tatoeba.org #954270 (CK) & #6383010 (odexed)\n",
      "If someone who doesn't know your background says that you sound like a native speaker, it means they probably noticed something about your speaking that made them realize you weren't a native speaker. In other words, you don't really sound like a native speaker.\tЕсли кто-то незнакомый говорит, что вы говорите как носитель языка, это значит, что он, вероятно, заметил что-то в вашей речи, что дало ему понять, что вы не носитель. Другими словами, вы не говорите как носитель.\tCC-BY 2.0 (France) Attribution: tatoeba.org #953936 (CK) & #10644468 (notenoughsun)\n",
      "Doubtless there exists in this world precisely the right woman for any given man to marry and vice versa; but when you consider that a human being has the opportunity of being acquainted with only a few hundred people, and out of the few hundred that there are but a dozen or less whom he knows intimately, and out of the dozen, one or two friends at most, it will easily be seen, when we remember the number of millions who inhabit this world, that probably, since the earth was created, the right man has never yet met the right woman.\tНесомненно, для каждого мужчины в этом мире где-то есть подходящая женщина, которая может стать ему женой, обратное верно и для женщин. Но если учесть, что у человека может быть максимум несколько сотен знакомых, из которых лишь дюжина, а то и меньше, тех, кого он знает близко, а из этой дюжины у него один или от силы два друга, то можно легко увидеть, что с учётом миллионов живущих на Земле людей, ни один подходящий мужчина, возможно, ещё не встретил подходящую женщину.\tCC-BY 2.0 (France) Attribution: tatoeba.org #7697649 (RM) & #7730831 (odexed)\n"
     ]
    }
   ],
   "source": [
    "!tail rus-eng/rus.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "R7Xb6_x_jVSl"
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2 \n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9UJcyA9ijlBd"
   },
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Zа-яА-ЯёЁ.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s)\n",
    "    s = s.strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "AAErcWmmkAWg"
   },
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, file_name, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open(file_name, encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(l.split('\\t')[0]), normalizeString(l.split('\\t')[1])] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "L62rzbEDkKmR"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TRulTVKDkL4R",
    "outputId": "91fe608b-1126-4b91-a5b0-583fdc3bbda3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 496059 sentence pairs\n",
      "Trimmed to 28336 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "rus 9895\n",
      "eng 4171\n",
      "['он играет у себя в комнате .', 'he is playing in his room .']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, file_name, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, file_name, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "file_name = 'rus-eng/rus.txt'\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'rus', file_name, True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUw1UDNwwMCM"
   },
   "source": [
    "# 2. Код обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "fdheWC9Le4Hn"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, rnnClass, input_size, hidden_size, num_layers=1, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnnClass = rnnClass\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, self.hidden_size)\n",
    "        self.rnn = rnnClass(self.hidden_size, self.hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "hN4Rr2ojwgNz"
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "\n",
    "def get_dataloader(batch_size, input_lang, output_lang, pairs):\n",
    "    n = len(pairs)\n",
    "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "\n",
    "    for idx, (inp, tgt) in enumerate(pairs):\n",
    "        inp_ids = indexesFromSentence(input_lang, inp)\n",
    "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
    "        inp_ids.append(EOS_token)\n",
    "        tgt_ids.append(EOS_token)\n",
    "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "\n",
    "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
    "                               torch.LongTensor(target_ids).to(device))\n",
    "\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "    return train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "JlZt6RSYwk-O"
   },
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "zdJemY9jwh0p"
   },
   "outputs": [],
   "source": [
    "def train(dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    target_length = len(dataloader)\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "\n",
    "        decoder_outputs, decoder_hidden, decoder_attention = decoder(\n",
    "            encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1))\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "GpDoBgkews3s"
   },
   "outputs": [],
   "source": [
    "def trainIters(train_dataloader, encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01, model_name=''):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  \n",
    "    plot_loss_total = 0 \n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "\n",
    "        loss = train(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "\n",
    "    return model_name, n_iters + 1, time.time() - start, print_loss_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
    "    with torch.no_grad(): \n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)  \n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor) \n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden) \n",
    "         \n",
    "        _, topi = decoder_outputs.topk(1) \n",
    "        decoded_ids = topi.squeeze()  \n",
    "\n",
    "        decoded_words = [] \n",
    "        for idx in decoded_ids: \n",
    "            if idx.item() == EOS_token: \n",
    "                decoded_words.append('<EOS>') \n",
    "                break \n",
    "            decoded_words.append(output_lang.index2word[idx.item()]) \n",
    "    \n",
    "    return decoded_words, decoder_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, input_lang, output_lang, n=10): \n",
    "    for i in range(n): \n",
    "        pair = random.choice(pairs) \n",
    "        print('>', pair[0]) \n",
    "        print('=', pair[1]) \n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang) \n",
    "        output_sentence = ' '.join(output_words) \n",
    "        print('<', output_sentence) \n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "D10TB2F70Jnz"
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame(columns=['model', 'epochs', 'time', 'loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "jNKrbgCv22li"
   },
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "batch_size = 16\n",
    "\n",
    "train_dataloader = get_dataloader(batch_size, input_lang, output_lang, pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtA_THCkfYpp"
   },
   "source": [
    "# 3. Sequence2Sequence Attention (на основе скалярного произведения)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "T8MqKfBG0XBk"
   },
   "outputs": [],
   "source": [
    "class DotAttention(nn.Module):\n",
    "    def __init__(self, hidden_size, dropout=0.1):\n",
    "        super(DotAttention, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, query, keys, valid_lens=None):\n",
    "        scores = torch.bmm(query, keys.transpose(1, 2)) / math.sqrt(query.shape[-1])\n",
    "\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(self.dropout(weights), keys)\n",
    "        return context, weights\n",
    "\n",
    "class AttnDot_DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
    "        super(AttnDot_DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = DotAttention(hidden_size)\n",
    "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input, hidden, target_tensor=None):\n",
    "        decoder_input = torch.empty(input.size(0), 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "\n",
    "            embedding = self.dropout(self.embedding(decoder_input))\n",
    "            context, attn_weights = self.attention(hidden.permute(1, 0, 2), input)\n",
    "            output, hidden = self.gru(torch.cat((embedding, context), dim=2), hidden)\n",
    "\n",
    "            outputs.append(self.out(output))\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1)\n",
    "            else:\n",
    "                _, topi = output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()\n",
    "\n",
    "        outputs = F.log_softmax(torch.cat(outputs, dim=1), dim=-1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return outputs, hidden, attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "id": "Af5kDQZ2YQnd",
    "outputId": "8c0ddd7d-2573-4ad7-b80a-f500225e1f0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30m 40s (- 276m 4s) (50 10%) 2.0279\n",
      "58m 17s (- 233m 9s) (100 20%) 1.5455\n",
      "87m 20s (- 203m 48s) (150 30%) 1.3327\n",
      "117m 3s (- 175m 35s) (200 40%) 1.1809\n",
      "147m 9s (- 147m 9s) (250 50%) 1.0636\n",
      "177m 37s (- 118m 24s) (300 60%) 0.9695\n",
      "208m 31s (- 89m 22s) (350 70%) 0.8915\n",
      "239m 15s (- 59m 48s) (400 80%) 0.8256\n",
      "269m 8s (- 29m 54s) (450 90%) 0.7696\n",
      "298m 49s (- 0m 0s) (500 100%) 0.7205\n"
     ]
    }
   ],
   "source": [
    "encoder1 = EncoderRNN(nn.GRU, input_lang.n_words, hidden_size).to(device)\n",
    "decoder1 = AttnDot_DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "df_result.loc[len(df_result)] = trainIters(train_dataloader, encoder1, decoder1, 500, print_every=50, model_name='Scaled dot product attention')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> меня беспокоит здоровье моеи матери .\n",
      "= i m worried about my mother s health .\n",
      "< i am concerned for to me me me me .\n",
      "\n",
      "> ты шутишь !\n",
      "= you re kidding !\n",
      "< you re you you you you you you . .\n",
      "\n",
      "> он быстрыи .\n",
      "= he s fast .\n",
      "< he am as i . . . . . .\n",
      "\n",
      "> я жду когда откроется магазин .\n",
      "= i m waiting for the store to open .\n",
      "< i re waiting on on her . . . .\n",
      "\n",
      "> меня интересует изучение немецкои культуры .\n",
      "= i am interested in studying german culture .\n",
      "< i m my my my my . . job job\n",
      "\n",
      "> вы еще молоды и неопытны .\n",
      "= you re still young and inexperienced .\n",
      "< you re is you you you you <EOS>\n",
      "\n",
      "> вы еще здесь .\n",
      "= you re still here .\n",
      "< you re here here here you here . . .\n",
      "\n",
      "> я танцовщица .\n",
      "= i m a dancer .\n",
      "< i aren i i as . . . child .\n",
      "\n",
      "> мы с томом хорошие друзья .\n",
      "= i m good friends with tom .\n",
      "< i m about with to to for . . .\n",
      "\n",
      "> он ответственен за это .\n",
      "= he is responsible for it .\n",
      "< he is all for for for that . . .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder1.eval() \n",
    "decoder1.eval()\n",
    "\n",
    "evaluateRandomly(encoder1, decoder1, input_lang, output_lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uL4nHMZLfaU6"
   },
   "source": [
    "# 4. Sequence2Sequence Attention (на основе MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "7u5hSrZvay3R"
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Va = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, keys)\n",
    "\n",
    "        return context, weights\n",
    "\n",
    "class AttnMLP_DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
    "        super(AttnMLP_DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = Attention(hidden_size)\n",
    "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input, hidden, target_tensor=None):\n",
    "        decoder_input = torch.empty(input.size(0), 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "\n",
    "            embedding = self.dropout(self.embedding(decoder_input))\n",
    "            context, attn_weights = self.attention(hidden.permute(1, 0, 2), input)\n",
    "            output, hidden = self.gru(torch.cat((embedding, context), dim=2), hidden)\n",
    "            output = self.out(output)\n",
    "            outputs.append(output)\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1)\n",
    "            else:\n",
    "                _, topi = output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()\n",
    "\n",
    "        outputs = F.log_softmax(torch.cat(outputs, dim=1), dim=-1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return outputs, hidden, attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QZR1a1qXl5p7",
    "outputId": "7a61b0b1-6eba-4569-9c92-5f438924a2f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30m 40s (- 276m 8s) (50 10%) 1.9864\n",
      "61m 22s (- 245m 29s) (100 20%) 1.4813\n",
      "93m 12s (- 217m 30s) (150 30%) 1.2704\n",
      "123m 35s (- 185m 23s) (200 40%) 1.1173\n",
      "153m 59s (- 153m 59s) (250 50%) 1.0012\n",
      "185m 11s (- 123m 27s) (300 60%) 0.9088\n",
      "215m 12s (- 92m 13s) (350 70%) 0.8330\n",
      "245m 0s (- 61m 15s) (400 80%) 0.7694\n",
      "274m 33s (- 30m 30s) (450 90%) 0.7156\n",
      "303m 59s (- 0m 0s) (500 100%) 0.6692\n"
     ]
    }
   ],
   "source": [
    "encoder2 = EncoderRNN(nn.GRU, input_lang.n_words, hidden_size).to(device)\n",
    "decoder2 = AttnMLP_DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "df_result.loc[len(df_result)] = trainIters(train_dataloader, encoder2, decoder2, 500, print_every=50, model_name='MLP attention')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> мне правда страшно .\n",
      "= i m really scared .\n",
      "< i m really tired . <EOS>\n",
      "\n",
      "> это человек на которого ты можешь положиться .\n",
      "= he s a man you can rely on .\n",
      "< he is an expert man you can do . <EOS>\n",
      "\n",
      "> ты успешен .\n",
      "= you re successful .\n",
      "< you re free at the right eye . <EOS>\n",
      "\n",
      "> мы почти все .\n",
      "= we re almost done .\n",
      "< we re almost there all . <EOS>\n",
      "\n",
      "> ты ужасно поешь .\n",
      "= you re a horrible singer .\n",
      "< you re a lot like the world . <EOS>\n",
      "\n",
      "> я рад принять ваше приглашение .\n",
      "= i m glad to accept your invitation .\n",
      "< i m glad to hear your voice . <EOS>\n",
      "\n",
      "> я устала этим заниматься .\n",
      "= i m tired of doing this .\n",
      "< i m tired of doing this too . <EOS>\n",
      "\n",
      "> он славныи .\n",
      "= he is nice .\n",
      "< he is a safe taller than his brother . <EOS>\n",
      "\n",
      "> я рад что приехал в австралию .\n",
      "= i m glad that i came to australia .\n",
      "< i m glad i m back to australia . <EOS>\n",
      "\n",
      "> ты очень открытая .\n",
      "= you re very open .\n",
      "< you re very very your brother to drive . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder2.eval() \n",
    "decoder2.eval()\n",
    "\n",
    "evaluateRandomly(encoder2, decoder2, input_lang, output_lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2OBe_uhWfbWB"
   },
   "source": [
    "# 5. Сводная таблица"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>epochs</th>\n",
       "      <th>time</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Scaled dot product attention</td>\n",
       "      <td>501</td>\n",
       "      <td>17930.004089</td>\n",
       "      <td>0.720537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLP attention</td>\n",
       "      <td>501</td>\n",
       "      <td>18239.724421</td>\n",
       "      <td>0.669153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  epochs          time      loss\n",
       "0  Scaled dot product attention     501  17930.004089  0.720537\n",
       "1                 MLP attention     501  18239.724421  0.669153"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.head()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "gUw1UDNwwMCM",
    "uL4nHMZLfaU6",
    "ZtA_THCkfYpp"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
